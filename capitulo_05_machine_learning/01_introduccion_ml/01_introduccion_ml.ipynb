{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/usm.png\" width=\"480\" height=\"240\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAT281 - 2° Semestre 2019\n",
    "## Aplicaciones de la Matemática en la Ingeniería"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos de la clase\n",
    "\n",
    "* Aprender conceptos básicos de machine learning en python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contenidos\n",
    "\n",
    "* [Introducción machine learning](#c1)\n",
    "* [Conceptos claves en machine learning](#c2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='c1'></a>\n",
    "## I.- Introducción machine learning\n",
    "\n",
    "<img alt=\"Machine Learning\" title=\"Machine Learning\" src=\"http://relopezbriega.github.io/images/machine-learning.jpg\">\n",
    "\n",
    "### ¿Qué es el Machine learning?\n",
    "Para comenzar, [Machine Learning](https://en.wikipedia.org/wiki/Machine_learning)  es un campo de las ciencias de la computación que se encarga de “aprender” dado un conjunto de datos. En otras palabras, se encarga de representar la estructura y generalizar comportamientos de los datos dados. Esta generalización es realizada mediante modelos matemáticos. \n",
    "\n",
    "Podemos resumir machine learning en cuatro puntos:\n",
    "\n",
    "-   Estudia y construye sistemas que pueden aprender de los datos, más\n",
    "    que seguir instrucciones explícitamente programadas.\n",
    "\n",
    "-   Conjunto de técnicas y modelos que permiten\n",
    "    el modelamiento predictivo de datos, reunidas a partir de la\n",
    "    intersección de elementos de probabilidad, estadística e\n",
    "    inteligencia artificial.\n",
    "\n",
    "-   Típicamente, alguien que trabaja en Machine Learning está en la Academia y busca realizar investigación y publicar artículos.\n",
    "\n",
    "-   Pregunta fundamental:\n",
    "    ¿Qué conocimiento emerge a partir de los datos? ¿Qué modelo/técnica\n",
    "    otorga la mejor predicción para estos datos?\n",
    "    \n",
    "Para poder avanzar en el estudio de machine learning es de vital importancia definir el concepto de modelo.\n",
    "\n",
    "### ¿Qué se entiende por modelo?\n",
    "\n",
    "Un [modelo](https://en.wikipedia.org/wiki/Mathematical_model) se entinde como:\n",
    "* Una representación abstracta y conveniente de un sistema.\n",
    "* Una simplificación del mundo real.\n",
    "* Un medio de exploración y de explicación para nuestro entendimiento de la realidad.\n",
    "\n",
    "Por otro lado, un modelo **no** es:\n",
    "\n",
    "* Igual al mundo real.\n",
    "* Un sustituto para mediciones o experimentos.\n",
    "\n",
    "Los modelos nos permiten: \n",
    "\n",
    "* reproducir experimentos donde factores no pueden ser fácilmente controlados.\n",
    "    * **Ejemplo**: Comportamiento de cápsula lunar en gravedad cero y al atravesar atmósfera a gran velocidad.\n",
    "\n",
    "\n",
    "* simplificar el entendimiento de sistemas complejos, al permitir el análisis y exploración de cada componente del sistema por separado.\n",
    "    * **Ejemplo**: Adelgazamiento de la capa de hielo polar por calentamiento global.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿ Qué tipos de problemas podemos abordar con machine learning?\n",
    "\n",
    "Los problemas que se pueden resolver con machine learning se pueden englobar en tres tipos: **aprendeizaje supervisado**, **aprendizaje no supervisado** y **aprendizaje reforzado**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Machine Learning\" title=\"Machine Learning\" src=\"https://miro.medium.com/max/2796/1*FUZS9K4JPqzfXDcC83BQTw.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprendizaje supervisado\n",
    "* El sistema aprende en base a datos estructurados o no\n",
    "estructurados. \n",
    "* Clasificados previamente (se conoce la respuesta).\n",
    "* El algoritmo produce una función que establece una\n",
    "correspondencia entre las entradas y las salidas\n",
    "deseadas del sistema.\n",
    "\n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcQp-m6CHvLgeRXeL_PQMUuXuLzOp6lMXxYVhSvdKbO6gUvVAFFJ\" width=\"400\" height=\"480\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprendizaje no supervisado\n",
    "* Modelo se construye usando un conjunto de datos\n",
    "como entrada, los cuales no han sido clasificados\n",
    "previamente.\n",
    "* El sistema tiene que ser capaz de reconocer patrones\n",
    "para poder etiquetar las nuevas entradas.\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Laith_Abualigah/publication/322455242/figure/fig1/AS:582970224644096@1516002340891/An-example-of-the-document-clustering.png\" width=\"400\" height=\"480\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprendizaje por refuerzo\n",
    "\n",
    "Aprendizaje por refuerzo o Aprendizaje reforzado es un área del aprendizaje automático inspirada en la psicología conductista, cuya ocupación es determinar qué acciones debe escoger un agente de software en un entorno dado con el fin de maximizar alguna noción de \"recompensa\" o premio acumulado. \n",
    "\n",
    "<img src=\"https://i.ytimg.com/vi/NxtEDLpJoqQ/maxresdefault.jpg\" width=\"700\" height=\"480\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿ Qué se necesita para aprender machine learning?\n",
    "\n",
    "Se necesita tener conocimientos de los siguientes tópicos.\n",
    "\n",
    "* **Algebra Lineal**\n",
    "* **Probabilidad y estadística**\n",
    "* **Optimización**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='c2'></a>\n",
    "## II.- Conceptos claves en machine learning\n",
    "\n",
    "### Esquema machine learning\n",
    "\n",
    "EL proceso de machine learning se puede resumir a grandes rasgo por el siguiente esquema.\n",
    "\n",
    "<img src=\"https://www.7wdata.be/wp-content/uploads/2017/06/Machine-Learning-Examplepng.png\n",
    "\" width=\"480\" height=\"480\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los pasos para construir un modelo de machine learning son:\n",
    "\n",
    "1. **Recolectar los datos**. Podemos recolectar los datos desde muchas fuentes, podemos por ejemplo extraer los datos de un sitio web o obtener los datos utilizando una [API](https://es.wikipedia.org/wiki/Interfaz_de_programaci%C3%B3n_de_aplicaciones) o desde una base de datos. \n",
    "\n",
    "2. **Preprocesar los datos**. Una vez que tenemos los datos, tenemos que asegurarnos que tiene el formato correcto para construir los modelos de machine learning. Es prácticamente inevitable tener que realizar varias tareas de preprocesamiento antes de poder utilizar los datos. Igualmente este punto suele ser mucho más sencillo que el paso anterior.\n",
    "\n",
    "3. **Explorar los datos**. Una vez que ya tenemos los datos y están con el formato correcto, podemos realizar un pre análisis para corregir los casos de valores faltantes o intentar encontrar a simple vista algún patrón en los mismos que nos facilite la construcción del modelo. En esta etapa suelen ser de mucha utilidad las medidas estadísticas y los gráficos en 2 y 3 dimensiones para tener una idea visual de como se comportan nuestros datos. En este punto podemos detectar valores atípicos que debamos descartar; o encontrar las características que más influencia tienen para realizar una predicción.\n",
    "\n",
    "4. **Entrenar el modelo**. Aquí es donde comenzamos a utilizar las técnicas de machine learning realmente. En esta etapa se entrenan los modelos con los datos que venimos procesando en las etapas anteriores. La idea es que los modelos puedan extraer información útil de los datos que le pasamos para luego poder hacer predicciones. \n",
    "\n",
    "5. **Evaluar el modelo**. En esta etapa ponemos a prueba la información o conocimiento que el modelo obtuvo del entrenamiento del paso anterior. Evaluamos que tan preciso es el modelo en sus predicciones y si no estamos muy conforme con su rendimiento, podemos volver a la etapa anterior y continuar entrenando el modelo cambiando algunos parámetros hasta lograr un rendimiento aceptable.  \n",
    "\n",
    "6. **Utilizar el modelo**. En esta ultima etapa, ya ponemos a nuestro modelo a enfrentarse al problema real. Aquí también podemos medir su rendimiento, lo que tal vez nos obligue a revisar todos los pasos anteriores. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los pasos 1,2,3 son los pasos que ya se han visto con detalle en este curso. Por otro lado, la etapa de modelamiento (entrenar, evaluar y predecir) será necesario introducir nuevos conceptos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Concepto de  Train set y Test set\n",
    "\n",
    "\n",
    "Al momento de entrenar los modelos de machine leraning, se debe tener un conjunto para poder entrenar el modelo y otro conjunto para poder evaluar el modelo. Es por esto que el conjunto de datos se separá en dos conjuntos: \n",
    "    \n",
    " * **Train set**: Conjunto de entrenamiento con el cual se entrenarán los algoritmos de machine learning.\n",
    " \n",
    "* **Test set**: Conjunto de testeo para averiguar la confiabilidad del modelo, es decir, cuan bueno es el ajuste del modelo.\n",
    "    \n",
    "<img src=\"https://d2h0cx97tjks2p.cloudfront.net/blogs/wp-content/uploads/sites/2/2018/08/1-16.png\n",
    "\" width=\"360\" height=\"240\" align=\"center\"/>\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿ Qué tamaño debe tener cada conjunto?\n",
    "\n",
    "La respuesta depende fuertemente del tamaño del conjunto de datos. Como regla empírica consideremos:\n",
    "\n",
    "| número de filas      | train set | test set |\n",
    "|----------------------|-----------|----------|\n",
    "| entre 100-1000       | 67%       | 33%      |\n",
    "| entre 1.000- 100.000 | 80%       | 20%      |\n",
    "| mayor a 100.000      | 99%       | 1%       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostremos un ejemplo en python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separando informacion:\n",
      "\n",
      "numero de filas data original :  150\n",
      "numero de filas train set     :  100\n",
      "numero de filas test set      :  50\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# print rows train and test sets\n",
    "print('Separando informacion:\\n')\n",
    "print('numero de filas data original : ',len(X))\n",
    "print('numero de filas train set     : ',len(X_train))\n",
    "print('numero de filas test set      : ',len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Concepto de overfitting y underfitting\n",
    "\n",
    "#### Overfitting\n",
    "El overfitting ocurre cuando el algoritmo de machine learning captura el ruido de los datos. Intuitivamente, el overfitting ocurre cuando el modelo o el algoritmo se ajusta demasiado bien a los datos. Específicamente, el sobreajuste ocurre si el modelo o algoritmo muestra un sesgo bajo pero una varianza alta. \n",
    "\n",
    "\n",
    "El overfitting a menudo es el resultado de un modelo excesivamente complicado, y puede evitarse ajustando múltiples modelos y utilizando validación o validación cruzada para comparar sus precisiones predictivas en los datos de prueba.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/578/1*Di7rY6ALXtkhlmlcKRSCoA.png\n",
    "\" width=\"360\" height=\"240\" align=\"left\"/>\n",
    "<img src=\"https://miro.medium.com/max/578/1*QzA45ATjeEbwv5f1G99GnQ.png\n",
    "\" width=\"360\" height=\"240\" align=\"rigt\"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underfitting\n",
    "\n",
    "El underfitting ocurre cuando un modelo estadístico o un algoritmo de machine learning no pueden capturar la tendencia subyacente de los datos. Intuitivamente, el underfitting ocurre cuando el modelo o el algoritmo no se ajustan suficientemente a los datos. Específicamente, el underfitting ocurre si el modelo o algoritmo muestra una varianza baja pero un sesgo alto.\n",
    "\n",
    "EL underfitting suele ser el resultado de un modelo excesivamente simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/578/1*kZfqaD6hl9iYGYXkMwV-JA.png\n",
    "\" width=\"360\" height=\"240\" align=\"left\"/>\n",
    "<img src=\"https://miro.medium.com/max/578/1*2RXJ2O-_c2ukaq5p-WQ9tQ.png\n",
    "\" width=\"360\" height=\"240\" align=\"rigt\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concepto de métricas\n",
    "\n",
    "En matemáticas, una métrica es una función que define una distancia entre cada par de elementos de un conjunto. Para nuetro caso, se define una función de distancia entre los valores reales ($y$) y los valores predicho ($\\hat{y}$).\n",
    "\n",
    "Defeniremos algunas métricas bajo dos tipos de contexto: **modelos de regresión** y **modelos de clasificación**.\n",
    "\n",
    "### Modelos de regresión\n",
    "\n",
    "Los modelos de regresión son ocupadas para predecir valores numéricos, por ejemplo, determinar el precio de una casa a partir de sus metros cuadrados. Para este caso, es necesario introducir el concepto de error. \n",
    "\n",
    "El **error** corresponde a la diferencia entre el valor original y el valor predicho,es decir:\n",
    "\n",
    "$$e_{i}=y_{i}-\\hat{y}_{i} $$\n",
    "\n",
    "<img src=\"https://www.jmp.com/en_hk/statistics-knowledge-portal/what-is-multiple-regression/fitting-multiple-regression-model/_jcr_content/par/styledcontainer_2069/par/lightbox_4130/lightboxImage.img.png/1548704005203.png\n",
    "\" width=\"480\" height=\"360\" align=\"rigt\"/>\n",
    "\n",
    "\n",
    "Lo que se busca es medir el error bajo cierta funciones de distancias o métricas. Dentro de las métricas ocupadas, se pueden tener:\n",
    "\n",
    "1. **Métricas absolutas**: Las métricas absolutas o no escalada miden el error sin escalar los valores. Las métrica absolutas más ocupadas son:\n",
    "\n",
    "*  **Mean Absolute Error** (MAE)\n",
    "\n",
    "$$\\textrm{MAE}(y,\\hat{y}) = \\dfrac{1}{n}\\sum_{t=1}^{n}\\left | y_{t}-\\hat{y}_{t}\\right |$$\n",
    "\n",
    "*  **Mean squared error** (MSE):\n",
    "\n",
    "$$\\textrm{MSE}(y,\\hat{y}) =\\dfrac{1}{n}\\sum_{t=1}^{n}\\left | y_{t}-\\hat{y}_{t}\\right |^2$$\n",
    "\n",
    "\n",
    "\n",
    "2. **Métricas Porcentuales**: Las métricas porcentuales o escaladas miden el error de manera escalada, es decir, se busca acotar el error entre valores de 0 a 1, donde 0 significa que el ajuste es perfecto, mientras que 1 sería un mal ajuste. Cabe destacar que muchas veces las métricas porcentuales puden tener valores mayores a 1.Las métrica Porcentuales más ocupadas son:\n",
    "\n",
    "*  **Mean absolute percentage error** (MAPE):\n",
    "\n",
    "$$\\textrm{MAPE}(y,\\hat{y}) = \\dfrac{1}{n}\\sum_{t=1}^{n}\\left | \\frac{y_{t}-\\hat{y}_{t}}{y_{t}} \\right |$$\n",
    "\n",
    "\n",
    "* **Symmetric mean absolute percentage error** (sMAPE):\n",
    "\n",
    "$$\\textrm{sMAPE}(y,\\hat{y}) = \\dfrac{1}{n}\\sum_{t=1}^{n} \\frac{\\left |y_{t}-\\hat{y}_{t}\\right |}{(\\left | y_{t} \\right |^2+\\left | \\hat{y}_{t} \\right |^2)/2}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics \n",
    "\n",
    "import numpy as np \n",
    "\n",
    "# a) Scale-dependent errors\n",
    "\n",
    "def mae(targets,predictions):\n",
    "    error = predictions - targets\n",
    "    return np.abs(error).mean()\n",
    "\n",
    "def mse(targets,predictions):\n",
    "    error = predictions - targets\n",
    "    return np.sqrt((error ** 2).mean())\n",
    "\n",
    "# b) Percentage errors\n",
    "\n",
    "def mape(targets,predictions):\n",
    "    error = predictions - targets\n",
    "    \n",
    "    if any(x == 0 for x in targets):\n",
    "        return np.inf\n",
    "    else:\n",
    "        return np.abs(error/targets).mean()\n",
    "        \n",
    "\n",
    "def smape(targets,predictions):\n",
    "    error = predictions - targets\n",
    "    sum_values = np.abs(predictions)+np.abs(targets)\n",
    "    \n",
    "    if any(x == 0 for x in sum_values):\n",
    "        return np.inf\n",
    "    \n",
    "    else:\n",
    "        return np.mean(np.abs(error)/sum_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores:\n",
      "\n",
      "originales:  [30.  -1.5 20.   7. ]\n",
      "predicho:    [25.5 -1.  18.   8. ]\n",
      "\n",
      "Metricas\n",
      "\n",
      "mae:    2.0\n",
      "mse:    2.52\n",
      "mape:   0.18\n",
      "smape:  0.1\n"
     ]
    }
   ],
   "source": [
    "# ejemplo \n",
    "\n",
    "y_true = np.array([30, -1.5, 20, 7])\n",
    "y_pred = np.array([25.5, -1, 18, 8])\n",
    "\n",
    "print('Valores:\\n')\n",
    "print('originales: ', y_true)\n",
    "print('predicho:   ', y_pred)\n",
    "\n",
    "print('\\nMetricas\\n')\n",
    "print('mae:   ',round(mae(y_true,y_pred),2))\n",
    "print('mse:   ',round(mse(y_true,y_pred),2))\n",
    "print('mape:  ',round(mape(y_true,y_pred),2))\n",
    "print('smape: ',round(smape(y_true,y_pred),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Modelos de clasificación\n",
    "\n",
    "Los modelos de clasificacion son ocupadas para predecir valores categóricos, por ejemplo, determinar la especie de una flor basado en el largo (y ancho) de su pétalo (y sépalo).Para este caso, es necesario introducir el concepto de matriz de confusión.\n",
    "\n",
    "La matriz de confusión es una herramienta que permite la visualización del desempeño de un algoritmo \n",
    "Para la clasificación de dos clases (por ejemplo, 0 y 1), se tiene la siguiente matriz de confusión:\n",
    "\n",
    "<img src=\"https://static.tildacdn.com/tild6630-3965-4833-b932-646530343464/9.svg\n",
    "\" width=\"480\" height=\"360\" align=\"rigt\"/>\n",
    "\n",
    "Acá se define:\n",
    "\n",
    "* **TP**: Verdadero Positivo\n",
    "* **FN**: Falso Negativo\n",
    "* **FP**: Falso positivo\n",
    "* **TN**: Verdadero Negativo\n",
    "\n",
    "En este contexto, los valores TP Y TN muestran los valores correctos que tuve al momento de realizar la predicción, mientras que los valores de de FN Y FP denotan los valores que me equivoque de clase.\n",
    "\n",
    "Los conceptos de FN y FP se pueden interpretar con la siguiente imagen:\n",
    "\n",
    "<img src=\"https://static.tildacdn.com/tild6436-6637-4562-b738-613433303838/error.jpg\n",
    "\" width=\"480\" height=\"360\" align=\"rigt\"/>\n",
    "\n",
    "\n",
    "En este contexto, se busca maximizar el número al máximo la suma de los elementos TP Y TN, mientras que se busca disminuir la suma de los elementos de FN y FP. Para esto se definen las siguientes métricas:\n",
    "\n",
    "\n",
    "* Accuracy:\n",
    "\n",
    "$$accuracy(y,\\hat{y}) = \\dfrac{TP+TN}{TP+TN+FP+FN}$$\n",
    "\n",
    "* Recall:\n",
    "\n",
    "$$recall(y,\\hat{y}) = \\dfrac{TP}{TP+FN}$$\n",
    "\n",
    "* Precision:\n",
    "\n",
    "$$precision(y,\\hat{y}) = \\dfrac{TP}{TP+FP} $$\n",
    "\n",
    "* F-score:\n",
    "\n",
    "$$fscore(y,\\hat{y}) = 2\\times \\dfrac{precision(y,\\hat{y})\\times recall(y,\\hat{y})}{precision(y,\\hat{y})+recall(y,\\hat{y})} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores:\n",
      "\n",
      "originales:  [1 1 0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 0]\n",
      "predicho:    [0 1 0 0 1 0 0 0 1 0 0 0 1 1 1 1 1 0 0 0]\n",
      "\n",
      "Matriz de confusion:\n",
      " \n",
      "[[6 3]\n",
      " [6 5]]\n",
      "\n",
      "Metricas:\n",
      " \n",
      "accuracy:    0.55\n",
      "recall:      0.45\n",
      "precision:   0.62\n",
      "f-score:     0.53\n"
     ]
    }
   ],
   "source": [
    "# ejemplo \n",
    "\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,recall_score,precision_score,f1_score\n",
    "\n",
    "np.random.seed(1)\n",
    "y_true = np.random.randint(2, size=20)\n",
    "y_pred = np.random.randint(2, size=20)\n",
    "\n",
    "print('Valores:\\n')\n",
    "print('originales: ', y_true)\n",
    "print('predicho:   ', y_pred)\n",
    "\n",
    "\n",
    "print('\\nMatriz de confusion:\\n ')\n",
    "print(confusion_matrix(y_true,y_pred))\n",
    "\n",
    "print('\\nMetricas:\\n ')\n",
    "print('accuracy:   ',round(accuracy_score(y_true,y_pred),2))\n",
    "print('recall:     ',round(recall_score(y_true,y_pred),2))\n",
    "print('precision:  ',round(precision_score(y_true,y_pred),2))\n",
    "print('f-score:    ',round(f1_score(y_true,y_pred),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problemas de los modelos y las métricas\n",
    "\n",
    "\n",
    "* Los modelos matemáticos tienen hipótesis que deben cumplir para segurar la calidad del ajuste, algo que muchas veces no se verifican al momento de ajustar modelos. \n",
    "\n",
    "* Se debe tener en cuenta que las métricas es una forma de medir distancia entre los valores originales y los predicho, y aunque las métricas sean \"buenas\", no asegura que capte correctamente la tendencia del fenómeno (overfitting).\n",
    "\n",
    "* En la medida que se pueda, graficar el fenómeno en estudio, sin embargo, cuando se tienen muchas dimensiones resulta más complejo de abstraerse del fenómeno.\n",
    "\n",
    "### Recomendaciones\n",
    "\n",
    "* Asegurese siempre de realizar un correcto análisis exploratorio de sus datos, para que el proceso de modelamiento con machine learning resulte exitoso.  \n",
    "\n",
    "* Si tiene la posibilidad de trabajar con varios modelos, pruebe con todos. Si es la cantidad de datos es muy grande, lo más recomendable es tener previamente una clasificación de modelos según el contexto del problema.\n",
    "\n",
    "* Las métricas son una buena referencia para definir la calidad del modelo y poder comparar entre un modelo y otro. Se recomienda escoger la métrica que bajo su investigación tenga más sentido.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "1. [Basic Concepts in Machine Learning](https://machinelearningmastery.com/basic-concepts-in-machine-learning/)\n",
    "2. [An Introduction to Machine Learning Theory and Its Applications: A Visual Tutorial with Examples](https://www.toptal.com/machine-learning/machine-learning-theory-an-introductory-primer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
